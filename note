
	  RollingUpdate	
		MaxSurge 
		  - Specifies the maximum number of pods the Deployment is allowed to create at one time. 
		  - You can specify this as a whole number (e.g. 5), or as a percentage of the total required number of pods 		
		         (e.g. 10%, always rounded up to the next whole number). 
		  - If you do not set MaxSurge, the implicit, default value is 25%.
		
		MaxUnavailable 
		  - specifies the maximum number of pods that are allowed to be unavailable during the rollout. 
		  - Like MaxSurge, you can define it as an absolute number or a percentage. 
	
Headless service 
	- If we don't need the default loadbalancing capability of services nor the single IP to service we use StatefullSet 
	- using Headless service we can get all the target pod ips, if we do nslookup.
	- It is created by sepcifying 'none' for ClusterIP
	- Headless service is usually used with StatefullSet controller.  


	- Headless service returns all the ips of the pods it is selecting.
	- headless service is created by specifying none for clusterIP 
	- headless service is usually used with statefulsets.

  2. Node affinity and anti-affinity 
		Node affinity 
			- nodeSelector with logical expressions is affinity 
			- using node affinity we can spread the pod schedule on worker nodes based on 
					- cpacity (memory-intense mode)
					- Availability zone (HA mode)
	node Anti-affinity (Inter-pod Affinity)
			- This is used to define whether a given pod should or should not be 
			  scheduled on a particular node based on conditional labels
 3. Pod eviction 

	- Kubernetes evict pods if the node resources are running out such as cpu, RAM and storage.
	
	HPA: HPA stands for Horizontal Pod Autoscaler. It is a feature in Kubernetes that automatically adjusts the number of replicas (pods) of a deployment or a replica set based on CPU utilization or other custom metrics. HPA ensures that the application has the right amount of resources (pods) available to handle the current traffic or workload, and it can scale up or down dynamically based on the defined metrics thresholds.

VPA: VPA stands for Vertical Pod Autoscaler. It is another feature in Kubernetes that adjusts the resource allocations (CPU and memory) of individual pods based on their actual resource usage. VPA monitors the resource utilization of each pod and adjusts the resource requests and limits to optimize the performance and efficiency of the pods, without manually updating the pod specifications.
	- Pod with failed state will be evicted first because they may not running but could still 
	  be using cluster resources and then k8s runs decision making based.
	  
 4 .Ingress
	Cloud loadbalancer are costly as most of the times billing will be per requests so 
	to avoid this the kubernetes solution is Ingress, we can run an external software based 
	load balancer in our cluster.
		
	1. Ingress controller 
		- This controller is used to execute the ingress resources which contains 
		  routing rules and brings the external traffic based on routing rules to the 
		  internal service.	
	    - This controller will automatically monitors the exiting resources and also 
		  identifies new ingress resources.
		- This will be a third party controllers (tools) which we need to install it 
          for one time in our cluster as controller.
		- We are using nginx as ingress controller.

	2. Ingress resources 
		- In k8s Ingress resource is type of object which is used to define routing rules 
		  based on path of incoming traffic to internal cluster service.
		- api for ingress resource networking.k8s.io/v1 	
		- Ingress can be used for revers proxy means to expose multiple services under same IP.
		- Ingress can be used to delete ssl/tls certificates.
	  
	  Kubernetes looks at two different reasons to make eviction decision: 
			1. QoS (Quality of Service) class. 
				For every container in the pod:
				  - There must be a memory limit and a memory request.
				  - The memory limit must equal the memory request.
				  - There must be a CPU limit and a CPU request.
				  - The CPU limit must equal the CPU request.

			2. Priority class.
				- A pod"s priority class defines the importance of the pod compared to other 
				  pods running in the cluster.
				- Based on the priority low to high pods will be evicted.  
		  		- Cluster autoscaler tools are mostly provided by public cloud providers
				
	Resource quotas and limits
	Count quota 
		- This quota is used to limit the max number of obejcts that we can have 
		  in a namepsace.
        Quota on CPU/RAM/Disk
	
	HPA and VPA
	HPA (Horizontal pod autoscaler 
	- HPA will automatically scales the number pf pod replicas using deployment, replicates, statefulSet based on CPU/memory threshold.
	- We need metric-server as a source for resource monitor for HPA

	VPA
	1. We need install metrics-server
	Deployment stratergies 
	(Zero downtime / High Availability)
	1. Rolling Update
		- A percent of pod will be updated. 	
		- By defualt max unavailable will be 25%.
		- By default deployment in k8s uses rolling update stratergy which means if I want use 
		  this stratergy I don'nt need to specify any parameters in spec file. 
		- Example: By default k8s automatically decides the percentage of keeping available pods.
		  usually one out 4 it updates (25%).
        2. Recreate 
		- The Recreate stratergy will bring all the old pods down immediately and the creates 
		  new updated pods to match the replica count.
        3. Blue-Green Deployment 
		- We keep 2 sets of similar environment in which one will be live called blue  
		  environment and the one which is not live is called as green. 
		- we update the new changes to green environment first which is not live and we 
		  swap/ redirect the traffic from blue to green environment.
		- Finally current green environment with new updates we rename it as blue and  
		  the current blue environment is renamed as green we use this for next release deployment.

	4. Canary Deployment 
		- A canary release is a software testing technique used to reduce the risk of 
		  introducing a new software version into production by gradually rolling out 
		  the change to a small subgroup of users, before rolling it out to the entire 
		  platform/infrastructure.
         Multi master cluster 	
	What is the size of the k8s cluster ?
		- we are manitaining different cluster for different environment
		- we have one big cluster and environments are maintained through namepsaces
		- always the count of master nodes should a odd number 
		- we are using loadbalancer / multiple people are working they may dd the worker nodes 
		  so I never kept exact count of nodes but on average we have 20 to 25 worker nodes.
	
	Why always the number of master nodes is odd number ?
		- Based on Quoram calculation (n/2+1) we get same quoram failure rate for odd number 
		  and its next even number of nodes, so it is better to use odd number nodes instead 
		  of even number and we start with minimum 3 master nodes.
		- Always tell odd number of nodes (any odd number starting with 3, 5, 7, 9)
		- Based on the quorum value we choose only odd number of nodes starting with 3 to 
		  achive better fault tollerance cluster.
		  
	restartPolicy: 
	   - This is a pod option on of job 
	   - Different policies are 
		Always 
		  - This is the default restartPolicy. Containers will always be restarted if they stop and 
		    even if they have completed successfully.	
	
		OnFailure
		   - only restart the pod if the container process exits with an error.
		   - If the pod is determined to be unhealthy and restarted by a probe then also pod 
	             will be restarted.
		
		Never 
		   - Pod are never restated even if the container inside pod exists with error.
		   
Common errors 
		ImagePullBackOff 
			- Docker image registry is not accessible 
			- Image name is incorrect.
		
		RunContainerError 
			- Configmap / secrets are missing 
			- volumes are not available 
		
		CrashLoopBackOff 
			- This error comes when probe check fails.
			- Error in docker image
	
